\documentclass[12pt]{book}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{latexsym, epsfig, ulem, cancel, multicol, hyperref}
\usepackage{graphicx, tikz, subfigure,pgfplots}
\usepackage{blindtext}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\setlength{\parindent}{0pt}
\usepackage{multirow}
\usepackage{mathtools}
\pgfplotsset{width=10cm,compat=1.9}
\usepackage{amsmath, amssymb, amsthm, graphicx, hyperref}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{multirow, multicol}
\usepackage{tikz}
\usepackage{comment}
\setlength{\parskip}{1ex}

\newcommand{\T}[0]{\top}
\newcommand{\F}[0]{\bot}
\newcommand{\liminfty}[1]{\lim_{#1 \to \infty}}
\newcommand{\limzero}[1]{\lim_{#1 \to 0}}
\newcommand{\limto}[1]{\lim_{#1}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\odd}[0]{\mathbb{Z} - 2\mathbb{Z}}
\newcommand{\lineint}[1]{\int_{#1}}
\newcommand{\pypx}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\divg}{\nabla \cdot}
\newcommand{\curl}{\nabla \times}
\newcommand{\dydx}[2]{\frac{d #1}{d #2}}
\newcommand{\sqbkt}[1]{\left[ #1 \right]}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\tribkt}[1]{\left< #1 \right>}
\newcommand{\abso}[1]{\left|#1 \right|}
\newcommand{\zero}{\{0\}}
\newcommand{\then}{\rightarrow}
\newcommand{\nonneg}{\Z^+ \cup \{0\}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand{\union}[2]{\bigcup_{#1}^{#2}}
\newcommand{\inter}[2]{\bigcap_{#1}^{#2}}
\newcommand{\openclose}[1]{\left( #1 \right]}
\newcommand{\closeopen}[1]{\left[ #1 \right)}
\newcommand{\compo}[2]{#1 e^{i #2}}
\newcommand{\laplase}{\bigtriangleup}

\newtheorem*{remark}{Remark}
\title{\textbf{Applied Partial Differential Equation}}
\author{Dennis Li}
\begin{document}
\maketitle

\tableofcontents
Course Grade Composition is one third midterm, two third final.
Exam questions will be directly from the homework with additional questions that asks you about the understanding of the material.

\chapter{Intro to PDE}

\section{Evolutionary PDEs}
In this section, we focus on finding a function $u(t)$. We are interested in how the function evolves in time. We will primarily ve studying this sort of PDEs.

An example being 
\[
\pypx{}{t} u = v \bigtriangleup u = \nu(\partial_{xx} + \partial_{yy} + \partial_{zz})u
\]
Where $\nu$ is some constant, and $\nu(t,\Vec{x})$ is our dependent variable or unknown. Since it depends on the independent variable, time and position, $t, \Vec{x}$ 

if we are only interested in one dimensional behavior, this simplifies to
\begin{align*}
\pypx{}{t}u = \nu \pypx{^2}{x^2} u 
\end{align*}
or we can use a different notation
\[
u_t = \nu u_{xx}
\]
This is the \textbf{one dimensional heat equation}

\subsection{Change of variable}
say we have $u(x,t)$, we change it to $u(x_+,x_-)$ by the rule that $x_+ = x+t$ and $x_- = x-t$

We want to think about it like $u\paren{x(x_+,x_-),t(x_+,x_-)}$

And we can represent them by $x = \frac{x_++x_-}{2}$ and $t = \frac{x_+-x_-}{2}$

\subsubsection{Example 1.1.1}
The following are examples of linear and homogeneous PDEs. Homogeneous means $u=0$ is a solution.

Every function here has constant coefficient, where the coefficient does not depend on time or space. It is hard to work with those with non-constant coefficient, but we can learn their property by working with constant ones. 

All example below are \textit{local} equations. It means that on both side of the equation, we are working with only with some $u(x,t)$. PDEs are always local, but on the verge of being non-local. But they are almost non-local since if you were to approximate the derivatives, you introduced some non-locality.
\begin{enumerate}
    \item $\partial_t u = vu_{xx}$\\
    This PDE is first order in time, second order in space, we will call this a second order equation.
    \item $\partial u = cu_x$\\
    This PDE is first order in time, first order in space, we will call this a first order equation.
    \item $\partial_{tt}u - c^2u_{xx}$
    This PDe is second order in time, second order in space, we will call this a second order equation.
\end{enumerate}

\subsection{Transport Equation}
Examine the following
\[
\partial_t u + c\partial_x u = 0
\]
We can actually factor the operators
\[
\paren{\partial_t + c\partial_x} u = 0
\]
This is a good fit to do change of variables, where we set $x_+ = x+ct$, and $x_- = x-ct$. Just as we have done before, this is essentially
\[
x = \frac{x_++x_-}{2} \quad t = \frac{x_+-x_-}{2c}
\]
Now we want to use our newly defined variable to change the original equation. To do so, we would need to figure out how to get rid of $\partial_t$ and $\partial_x$. We can look at them individually. 
\[
\pypx{}{t} u = \pypx{x_+}{t}\pypx{u}{x_+} + \pypx{x_-}{t}\pypx{u}{x_-} = c\paren{u_{x_+} - u_{x_-}}
\]
Here, we see that $\pypx{x_+}{t}$ is simply $c$, and $\pypx{x_-}{t}$ is simply $-c$. Similarly, we can do the same process to $\partial_x$
\[
c \pypx{}{x}u = c\paren{u_{x_+} + u_{x_-}}
\]
And therefore
\[
\paren{\pypx{}{t}+c\pypx{}{x}}u = 2cu_{x_+} = 0
\]
And this means that $u_{x_+} = 0$, indicating that means $u$ is not a function of $x_+$. Therefore
\[
u(x_+,x_-) = A(x_-) 
\]
This means that \textbf{any} function with respect to $x_-$ or any $A(x-ct)$ solves this PDE.  And this is the general solution of this partial differential equation.

How would we interpret this solution. This solution tells us some property about the time evolution of all the solution. As time evolves, the entire function moves to the $+x$ direction. This is in fact a wave. 

If there were to be an initial value to be our $u_{init}$, this means that there would be only one solution, with exactly one initial condition. This is the \textbf{initial value problem} in PDE. Basically, the solution tells you how the function transports in time, and the initial data tells us what kind of equation is being transported. 

Now we incorporate the initial value into our PDE problem. 
\[
\begin{cases}
    \partial_t u + c\partial_x u = 0 & t>0,\; -\infty < x < \infty\\
    u(x,t=0)=u_{i}(x) &\forall x \in \R
\end{cases}
\]
We can think of our initial value, an entire function, as an infinite degree information that is needed to nail down the equation. And we can also think of it like follows.
\[
\int_D u_t(t,x) \; dt = u(t,x) + A(x)
\]
Taking an integral of a partial derivative with respect to $t$ leaves you an entire free function of $x$, therefore we would need a function of $x$ as our initial value. 

\subsubsection{Numerical Approximation}
Now we look at the transport equation with initial value. Here, if we have condition
\[
\begin{cases}
    u_t+c\partial_x u = 0 & t>0 \; x\in \R\\
    u(x,t=0) = u_i{x}
\end{cases}
\]
We have solved that $u(x,t) = u_i(x-ct)$. What if we want to approximate the solution without using any calculus. We would first define a small interval on the $x-axis$, we would call it $\delta$. We define $x_j = j\delta$. And the function can now be written as
\[
u(x_j,t) = u(j\delta,t)
\]
The function essentially became a infinite dimensional vector
\[
\mathbf{u}^{N} = \paren{u_1,u_2,\ldots,u_N} \quad \forall j \in \{1,2,\ldots,N\}
\]
And the derivative with respect to $x_j$ will become
\[
\partial_x u(x_j) \simeq \frac{u(x_{j+1})-u(x_j)}{\delta}
\]
And we can solve it like an ODE
\[
\dydx{}{t}u_j = \frac{-c}{\delta}(u_{j+1}-u_j)
\]
Where
\[
u_j(t) = u(x_j,t) = u(j\delta,t)
\]
We have successfully approximate the PDE with a series of ODEs. We can see that the smaller we make the interval, the better the approximation. Therefore it is a good way to think of PDE as an infinite collection of ODEs. 

\subsubsection{Physical Derivation of Transport Equation}
Imagine we have a pipe where water flows through it at speed $c$. The water is contaminated and the pollutant has density as a function of position and time, $u(x,t)$, and has dimensions $g/mm$.  

Now we imagine $x=0$ as the beginning of the pipe, and $x=b$ as the cut off point where we are interested, we define a function $M(b,t)$ to be the amount of pollutant in the section from $x=0 \to x=b$. Or it can be written as
\[
M(b,t) = \int_{0}^{b}u(x,t)\;dx
\]
And after a certain time $\tau$ after time $t$, the amount of pollutant can be characterized with
\[
M(b+c\tau,t+\tau) = \int_{c\tau}^{b+c\tau}u(x,t)\;dx
\]
Where $c\tau$ is the distance the pollutants moved along with the speed of the water in the tube. 
If we think of the blob of pollutant be moving through the pipe with the water, we can model it like the follows. 
\[
M(b,t) = M(b+c\tau,t+\tau)
\]
And sequentially
\[
\int_{0}^{b}u(x,t)\;dx = \int_{c\tau}^{b+c\tau}u(x,t)\;dx
\]
We are basically transporting this blob of stuff in the pipe. If we would take the partial dirivative of this integral with respect to $b$ and $\tau$, we have
\begin{align*}
    u(b,t) = u(b+c\tau,t+\tau)\\
    \left. 0 = u_t + cu_b \right|_{t=0}(b,t)
\end{align*}
We have obtained the transport equation
\[
u_t + c\partial_b u = 0, \;\; u(b,t)
\]

\subsubsection{Physical Derivation of Diffusion Equation}
Now if the pipe has no definitive starting point, and is starting at an arbitrary position $x_0$, and we have the cutoff $x_1$. The pollutant comes in from $x_0$ and leaves at $x_1$. 

If the water is not moving, but the pollutant is spreading out in the water, the physical law that characterize this behavior is called the \textit{Fisch's Law}. And it says
\[
-R \pypx{}{x}u(x,t),\; R > 0
\]
This expression characterize the flow rate of the pollutants.
We define a function that relates the amount of pollutant with only time.
\[
M(t) = \int_{x_0}^{x_1}u_(x,t)\; dx
\]
We can differentiate the equation with respect to $t$, and obtain
\[
M'(t) = \int_{x_0}^{x_1}u_t(x,t)\; dx
\]
And this is equivalent as the flow rate of the pollutant, therefore
\[
M'(t) = \int_{x_0}^{x_1}u_t(x,t)\; dx = -R\partial_{x_0}u(x_0,t) + R\partial_{x_1}u(x_1,t) 
\]
And we would obtain the \textbf{diffusion equation}, or the \textbf{heat equation}.
\begin{align}
u_t(x,t) = Ru_{xx}(x,t)
\end{align}
This would eventually give us 
\[
u_t = c\partial_x u
\]
Which is indeed the transport equation. 



\subsection{Wave Equation}
\[
u_tt - c^2\nabla^2 u =0
\]
Now we look at this partial differential equation
\begin{align}
    u_{tt} - c^2u_{xx} = 0 \quad t>0,\; -\infty<x<\infty
\end{align}
And the initial value will consist of 2 functions of $x$ since this is second order in time. 
\begin{align}
    u(x,t=0)=u_{i}(x)\\
    u_t(x,t=0)=v_{in}(x)
\end{align}
And this is the one dimensional linear wave equation in. Now how do we solve it. We can factor the operators like before
\[
\paren{\partial_{tt}-c^2\partial_{xx}}u = 0
\]
And we can factor it further, treating the second derivative as some sort of a square, and get
\[
\paren{\partial_t + c\partial_x}\paren{\partial_t - c\partial_x}u = 0
\]
And we can use the same change of variable as before, where
\[
x_+ = x+ct \quad x_- = x-ct
\]
We would obtain
\[
\frac{\partial}{\partial x_+}\frac{\partial}{\partial x_-} u = 0
\]
We by observation of this equation, we can see that the solution can be obtained like follows.
\[
\int \frac{\partial}{\partial x_+}\frac{\partial}{\partial x_-} u \; dx_+= A'(x_-) 
\]
and we have
\[
\int \frac{\partial}{\partial x_-} u \; dx_-= \int A'(x_-) \; dx_-
\]
If we define $\dydx{}{x_-}A(x_-)=A'(x_-)$, this would give us
\[
u(x_+,x_-)=A(x_-)+B(x_+)
\]
And if we substitute back, we have
\[
u(x_+,x_-)=A(x-ct)+B(x+ct)
\]
Think of it like the function is composed of one function of $x_-$ and another function of $x_+$, such that when you carry out the sequence of these partial derivatives you get 0. 

We have 2 degrees of infinite solution for $A(x_-)$ and $B(x_+)$. To obtain the precise function that solves certain problems, we will need 2 initial value, or 2 initial function to obtain it. 

So now, we use the 2 functions we received at the beginning as our initial value and solve for the exact solution.  We would plug the solution in to our initial value.
\[
u(x,t=0)=u_{i}(x)
\]
This means that
\[
\left. A(x-ct)+B(x+ct)\right|_{t=0} = A(x)+B(x) = u_{i}(x)
\]
And the other initial value gives us
\[
\left. A'(x-ct)+B'(x+ct)\right|_{t=0} =-cA'(x)+cB'(x) = u_{i}(x)
\]
We can take the derivative of the first equation, and receive the following set of equations
\[
\begin{cases}
    A'(x)+B'(x)=u'_{i}(x)\\
    cB'(x)-cA'(x)=u_{i}(x)
\end{cases}
\]
We can multiply the first equation by $c$ and add two functions. After some manipulation, we will have
\[
B'(x) = \frac{1}{2} u'_{in}(x) + \frac{1}{2c}u_{i}(x)
\]
And we can do the same process and subtract the two equations and get
\[
A'(x) = \frac{1}{2} u'_{i}(x) - \frac{1}{2c}u_{i}(x)
\]
Now we integrate the both of these solutions
\[
A(x-ct)=\int_{-\infty}^{x-ct} A'(y) \; dy = \frac{1}{2}u_{i}(x-ct)-\frac{1}{2c}\int_{-\infty}^{x-ct}u_{i}(y)\;dy
\]
\[
B(x+ct)=\int_{-\infty}^{x+ct} B'(y) \; dx = \frac{1}{2}u_{i}(x+ct)+\frac{1}{2c}\int_{-\infty}^{x+ct}u_{i}(y)\;dy
\]
And we can rewrite the solution
\[
u(x,t) = \frac{1}{2}u_{i}(x-ct)-\frac{1}{2c}\int_{-\infty}^{x-ct}u_{i}(y)\;dy + \frac{1}{2}u_{i}(x+ct)+\frac{1}{2c}\int_{-\infty}^{x+ct}u_{i}(y)\;dy 
\]
We can therefore simplify the integrals, and finally obtain the final solution to the one dimensional wave equation.
\begin{align}
u(x,t) = \frac{1}{2}u_{i}(x-ct)+ \frac{1}{2}u_{i}(x+ct)-\frac{1}{2c}\int_{x-ct}^{x+ct}u_{i}(y)\;dy 
\end{align}
What happened here is we integrated the function from $-\infty$ to a variable we defined, such as $x+ct$ or $x-ct$. This effectively swapped the variable in the integral to something we desire.

We have derived the general formula to solve the wave equation
\[
u(x,t) = \frac{1}{2}\sqbkt{\phi(x+ct)+\phi(x-ct)}+\frac{1}{2c}\int_{x-ct}^{x+ct} \psi(s) \;ds
\]
Where $\phi$ is the function $u(x,t=0)$ and $\psi$ is the function $u_t(x,t=0)$.


\section{Diffusion Equation}
Also called heat equation, will be the center of discussion for this section.
\[
\partial_t u = k\partial_{xx}u
\]
\[
t>0\;\; -\infty < x <\infty \;\; \nu\in +\R
\]
We are looking at the one dimensional diffusion equation. In 3 dimension, we will have
\[
\partial_t u = \nu\nabla^2u
\]
We will currently look at only one dimensional. In terms of initial value, we have to specify
\[
\begin{cases}
    \partial_t u = \nu\partial_{xx}u\\
    t>0\;\; -\infty < x <\infty \;\; \nu\in +\R\\
    u(x,t=0) = u_i(x)
\end{cases}
\]
We are looking at something that is linear and homogeneous. This is important since this allows the linear combination of solutions to also be solutions. Now how to we solve for this equation? We take an educated guess that the solution may take the following form
\begin{large}
\[
u(x,t) = e^{i(kx-\omega t)} \quad k,\omega \in \C
\]
\end{large}
Then we can substitute it back into the diffusion equation, and obtain the following equation
\[
-i\omega e^{i(kx-\omega t)} = -\nu k^2 e^{i(kx-\omega t)}
\]
And the term $e^{i(kx-\omega t)}$ can be canceled. We have
\[
-i\omega = -\nu k^2
\]
After simplification, we have
\[
\omega(k) = -i\nu k^2
\]
Substitute it back in, we have
    \[
    u(x,) = e^{i(kx+i\nu k^2 t)}
    \]
Therefore our final solution to this equation is
\begin{large}
    \[
    u(x,t;k) = e^{ikx}e^{-\nu k^2 t} \quad \forall k \in \C
    \]
\end{large}
How do we interpret this solution. We can first analyze what happens if $k \in \C - \R$. If $k$ has imaginary component, the function either blows up at $-\infty$ or $\infty$. Therefore we only accept real values of $k$. And the actual solution that makes sense is
\begin{large}
    \[
    u(x,t;k) = e^{ikx}e^{-\nu k^2 t} \quad \forall k \in \R
    \]
\end{large}
We now have a collection of solutions that is bounded in space and decays in time. We can also define a special case where we can imagine something diffusing in a closed loop, or a periodic boundary condition.
\[
u(x+L,t) = u(x,t) \quad L = 2\pi n
\]
Now we are interested in the periodic behaviour of the function. We know that
\[
e^{ik(x+L)} = e^{ikx}
\]
It is easy to see that the function has a period of $2\pi j$, where $j \in \Z$. Therefore $kL = 2\pi j$
\[
e^{ikL} = 1 \quad k_j = \frac{2\pi j}{L}
\]
If we would look like the rectangular form, we have
\[
e^{\frac{2\pi i}{L}jx} = \cos\paren{\frac{2\pi}{L}jx} + i\sin\paren{\frac{2\pi}{L}jx}
\]
The parameter $j$ determines how many wave you are shuffing into a period of $L$, and $j$ is called the wave number. 

Our most general solution for the diffusion equation is
\begin{large}
    \[
    u_{gen}(x,t) = \sum_{j=-\infty}^{\infty}c_je^{i\sqbkt{k,t}}e^{-\nu k_j^2 t}
    \]
\end{large}
For our periodic case, we have one of the term equals to 1, so we can simplify it
\begin{large}
    \[
u_{L}(x) = \sum_{j=-\infty}^{\infty}c_j e^{ik_j x}, \quad k_j = \frac{2\pi j}{L}
\]
\end{large}
We have to choose $c_j$ carefully such that the series converges, maybe with something like $c_j = \frac{1}{j^2}$. For this to have a specific solution, our initial condition has to provide an $L$ periodic function for all $x$. Our initial condition can be given as
\[
u(x,t=0) = u_i(x) = \sum_{j=-\infty}^{\infty}c_j e^{ik_j x}
\]
So how do we figure out $c_j$. We know that the following equality has to establish
\[
\sum_{j=\infty}^{\infty} c_j \int_{0}^{L}\paren{e^{i(k_j-k_n)x}}\,dx
\]
This then gives us
\[
\sum_{j=\infty}^{\infty} c_j  \paren{\left.\frac{e^{i(k_j-k_n)x}}{i(k_j-k_n)}\right|_{0}^L}
\]
When $j\neq n$, we end up with $e^{2\pi(j-m)}-1$ in the numerator, this means that it is always $0$. So we should investigate what $j=n$ sees. We have the following
\[
c_j \int_{0}^{L}\paren{e^{i(k_j-k_n)x}}\,dx = c_j \int_{0}^{L}1\,dx = c_nL
\]
Now we can solve $c_n$
\[
c_n = \frac{1}{L}\int_0^L e^{ik_nx}u_i(x)\,dx
\]
Therefore, if our initial function is $L$ periodic and smooth, our solution can be written as
\[
f(x) = \sum_{j=-\infty}^\infty e^{ik_jx}c_j, k_j = \frac{2\pi j}{L}
\]
Where
\[
c_j = \frac{1}{L}\int_0^L e^{ik_jx}(\lambda)\,dx
\]
This is the Fourier series of a function. And we have the full complex form the Fourier series. The sine and cosine one is the \textit{real} form of the Fourier series. 

We can rewrite $c_j$ with the following notation
\[
\hat{f}_j = \frac{1}{L}\int_0^L e^{ik_jx}(\lambda)\,dx
\]
It tells you how much of the function $f$ is oscillating with periodically with $j$ waves. It is another representation of the function that measures how much its oscillating. 

Now we have learned the periodic representation of a periodic function. 

\subsubsection{L period solution}
If we have a square wave that is defined as follows
\[
sq(x) = \begin{cases}
    1 & 0\leq x\leq \pi\\
    0 & \pi < x < 2\pi
\end{cases}
\]
We can represent it as
\[
sq(x) = \sum_{j=-\infty}^\infty e^{ijx}c_j \quad k_j = \frac{2\pi j}{2\pi}
\]
And we have obtain the coefficient
\[
c_j = \frac{1}{2\pi}\int_0^\pi e^{-ijx}\,dx
\]
Carry out, we have
\[
c_j = \frac{1}{2\pi}\paren{\left. \frac{e^{-ijx}}{-ij}\right|_0^\pi}
\]
This gives you 
\[
c_j = \frac{i}{2\pi j}\paren{e^{-ij\pi}-1}
\]
if we would use the Euler's identity
\[
c_j = \frac{1}{2\pi j }\paren{\cos\paren{\pi j} - i\sin\paren{\pi j} - 1}
\]
And now we can throw it back to the original summation. We see that the series converges very slowly, but since the numerator of $c_j$ is periodic, it does converge conditionally. The reason why it converges so slowly is because of the massive jump of the square wave takes a bunch of sinusoidal functions to approximate. If the function were to be nicer, everything works out nicely. 
\subsubsection{2l period solution}
The initial value problem of the heat equation is given by
\[
\begin{cases}
    u_t = \nu u_{xx} & t>0,\; 0\in\R \\
    u(x,t=0)=u_i(x)\\
    u_i(x+2l) = u_i(x) & \forall x\in \R
\end{cases}
\]
We have solved it for $L$ period, now we want to solve it for $2L$ period. In this case, the formula would look like
\[
u(t,x) =\sum_{j=-\infty}^{\infty}c_j e^{ik_j x}e^{-\nu k_j^2 t} \quad k_j = \frac{j\pi}{l},\; j\in \Z
\]
Where the coefficient is
\[
c_j =\frac{1}{2l} \int_{-l}^{l}e^{-ik_jx}u_i(x)\,dx
\]
We have obtained the solution to heat equation. 

\section{Fourier Series}
If we would look at the initial condition, or $t=0$ situation of the heat equation, we have
\[
u_i(x) = \sum_{j=-\infty}^{\infty} c_je^{ik_j x}
\]
Here, $j$ is the wave number, of the amount of wave that fits into a period. We now have a powerful tool to represent a general function with an infinite series of oscillating functions. 

$c_j$ tells you how much the initial function looks like the basic wave $e^{ik_j x}$. It is just a different  way to represent the initial function, that is why it sometimes is denoted as $\hat{f}_j$.

Beyond the time $t=0$, if we would like to see what the function looks like at $t=t_0$, a fixed time stamp, it still behaves similarly. Its just that we have some extra parameter to describe what the function looks like.
\[
u(t_0,x) =\sum_{j=-\infty}^{\infty}\paren{c_je^{-\nu k_j^2 t_0}}  e^{ik_j x}
\]
We see that if $t \neq 0$, we have an extra $e^{-t}$ term to help the sequence converge. The summation for the initial function converges very slowly, and is hard to approximate. But as time evolves, it almost instantaneously becomes smoother, as seen by this extra coefficient that decays exponentially very quickly. This helps the series converges much faster than the initial case. This is the property of the diffusion equation, and it reflects the physical behavior of diffusion. 

Think of this physically as a copper wire that is heated regionally, and then contact it with another piece of copper. The heat difference at contact is a clear boundary, like a square wave function, but immediately after contact, the heat diffuses and the curve becomes completely continuous and smooth.

Another important fact about this series is that the convergence is uniform, meaning if you take a finite sum of terms, then the error is uniformly distributed across all $x$. To analyze error in discontinuity, we conduct the following
\[
f_N(x) =  \sum_{j=-N}^{N} c_je^{i k_j x} \rightarrow \frac{1}{2}\paren{f(x+\delta)+f(x-\delta)}
\]
It is basically taking the middle point of the discontinuous junction. 

We notice that we have an imaginary term in our Fourier series. We started from a real function and is suppose to end up in the real world. What do we do to fix this problem? Apparently both $c_j\in C$ and $e^{i}\in\C$. Since the result is very likely to be real, we should see the imaginary part  in the product of these term goes away somehow. Let's take a look. 

If we take a look at $-j$, we have
\[
c_{-j} =\frac{1}{2l} \int_{-l}^{l}e^{ik_jx}u_i(x)\,dx
\]
But this is actually the conjugate of the original integrand.
\[
c_{-j} =\frac{1}{2l} \int_{-l}^{l}\overline{\paren{e^{-ik_jx}u_i(x)}}\,dx = \overline{c_j}
\]
This is possible because $u(x)$ is real. We can write out the original sum into the positive and negative components. 
\[
c_j = c_0 + \sum_{j=1}^{\infty}c_je^{-ik_jx} + \sum_{j=1}^{\infty}c_je^{ik_jx}
\]
But we have a complex number added to its conjugate. The imaginary part cancels and leaving only the real part. And obviously $c_0$ is real, since $c_0$ is
\[
c_0 = \frac{1}{2l}\int_{-l}^{l}u_i(x)\,dx
\]
And this has showed that $c_j \in \R$. And notice that $c_0$ is actually the average heat distribution in the period $2l$. Now we look at the original sum.
\[
u_i(x) = \sum_{j=-\infty}^{\infty} c_je^{ik_j x} 
\]
Just as before, we break it into two parts
\[
u(x) = \sum_{j=1}^{\infty} c_je^{ik_j x} + \sum_{j=1}^{\infty} c_je^{-ik_j x}
\]
And we have showed that $c_j \in \R$, we can use the same argument to say that $u_i(x)$ will also be real. And if we would expand it with Euler's identity, and decompose them into individual component of $c_j$, we have the \textit{real} form of the Fourier series
\[
a_0 = c_0 = \frac{1}{2l}\int_{-l}^l u_i(x)\,dx
\]
\[
a_j = \frac{1}{l}\int_{-l}^{l}\cos\paren{ k_j x }u_i(x)\,dx
\]
\[
b_j = \frac{1}{l}\int_{-l}^{l}\sin \paren{k_j x }u_i(x)\,dx
\]
These are the coefficients of the series, and the original series is
\[
u_i(x) = a_0 + \sum_{j=1}^{\infty} a_j\cos k_ix +b_j\sin k_i x
\]
Now we have the original Fourier series. The imaginary form is in fact more powerful. But it is a personal choice really. Do remember they are, as a matter of fact, equivalent. 

















\end{document}